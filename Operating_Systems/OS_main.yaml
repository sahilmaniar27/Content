---
Subject:
  name: Operating Systems
  subtopics:
    - Introduction
    - Process & Threads
    - Scheduling
    - Memory & Address Space
    - Virtual memory & paging
    - Concurrency
    - Synchronization
    - Persistence
    - Miscellaneous

Process & Threads:
  - Process:
    Concept of Process and Process Attributes:
      References:
        - Gate Lectures by Ravindrababu Ravula: https://youtu.be/ucVm_arB-fw
        - Neso Academy: https://youtu.be/OrM7nZcxXZU
        - Operating System Concepts Peter B. Galvin: Chapter 3, section 3.1
      Practice_questions:
        - Question_1: |
            State true or false.
            A process can be multiple states at a time.
          Company_tags: None
          Level: None
          Correct_answer: "False"
          Answers:
            - Hint: A process can only exist in 1 state at a time.
            - Solution: A process can only be in one state at a time. As in, it can be in ready state or blocked state or swapped state, etc.
        - Question_2: |
            A file is opened by the user. What will be the changes in Local Descriptor Table(LDT) and Global Descriptor Table(GDT)?
            Moreover, if 2 different processes have opened one instance each of a file and one of the process closes it,
            what will be the changes in the LDT and GDT?
          Company_tags: None
          Level: None
          Answer:
            Hint: GDT has an entry even if one instance is there.
            Solution: |
                LDT is also called a per-process descriptor table and GDT is called a system wide descriptor table.When you initially open a
                file, both LDT and GDT make new entries of the file. But, if it is already opened by even one process, the GDT only increases
                the counter. If an instance of a file opened by other process nut a new process opens it, a new instance is made in LDT.
                So, when a file is closed by one of the processes, given that only a single instance is opened by each process, only the
                counter in GDT is decreased in the GDT, but in LDT the entry is deleted (as only one instance was opened and that to was
                closed). There is an entry in the GDT for a file as long as there is at least one instance of the file opened by a process.
        - Question_3: |
            Which of the following is correct about Page Table?
            S1: It keeps track of main memory associated with the process.
            S2: It keeps track of secondary memory to processes.
            S3: It keeps the information needed to manage Physical Memory.
            S4: It keeps track of protection attributes of main and secondary memory.
          Company_tags: None
          Level: None
          Options:
            - 1: S1
            - 2: S2
            - 3: S3
            - 4: S4
          Correct_answer: S3
          Answer:
            - Reference: https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/8_MainMemory.html (It's section 8.1.3)
            - Hint: The OS only generates Logical Address.
            - Solution: |
                S3 is wrong because OS only generates Logical Address so Memory Table, also known as page table, keeps track of virtual
                memory of the process. Note that user programs never see physical addresses. User programs work entirely in logical
                address space, and any memory references or manipulations are done using purely logical addresses. Only when the address
                gets sent to the physical memory chips is the physical memory address generated.

        - Question_4: Which of the following attributes of a thread are private to itself?
          Company_tags: None
          Level: None
          Options:
            -1: Heap Space
            -2: Stack Space
            -3: File Descriptors
            -4: Signal Handler
          Correct_answer: 2
          Answer:
            - Hint:
            - Solution: |
                A thread shares with its peer threads its Code section Global data section, Operating-system resources, Process instructions,
                Open files (descriptors), Signal and signal handlers, Current working directory and User and group id. But, Stack space,
                Signal Masks and Register Set is private for a thread. It also has a separate return value for itself (errno).

        - Question_5: Which of the following is an indirect way of communication between processes (IPC)?
          Company_tags: None
          Level: None
          Options:
            -1: Shared Memory
            -2: Signals
            -3: Mailbox
            -4: Passing Pointers
          Correct_answer: 3
          Answer:
            - Hint:
            - Solution: |
                The correct option is c. This is because we pass signals explicitly to the processes we need to communicate to and shared memory
                is with the processes we want to share it with (processes need to join themselves to the shared memory block). Similar is the
                case with passing pointers. Mailbox is called a port. It consists of queue of messages. Sender keeps the message in mailbox and
                receiver picks them up.
    Fork and Exec system calls:
      References:
        - Neso Academy (YouTube): https://www.youtube.com/watch?v=IFEFVXvjiHY
        - Techtud (YouTube): https://www.youtube.com/watch?v=PwxTbksJ2fo
        - Operating System Concepts by Abraham Silberschatz, Peter B. Galvin and Greg Gagne: Chapter 3, Section 3.3
        - GeeksForGeeks: https://www.geeksforgeeks.org/difference-fork-exec/
      Practice_questions:
        - Question_1: How is PID assigned to a process?
          Company_tags: None
          Level: None
          Options:
            - 1: Randomly
            - 2: It is the next vacant PID
            - 3: It is the next vacant PID from the start
            - 4: It is the least vacant PID
          Correct_answer: 2
          Answer:
            - Hint: Go through how PID is assigned
            - Solution: |
                PID is always assigned as next vacant PID. For ex. if the current PID is x, the next PID will be the next vacant PID slot after x.
                It maybe x+1, x+2 or even 3, 4, etc. It is determined by circular search.
        - Question_2: |
            Read the following piece of code carefully.
            int main(){
              printf("Hello, I am in main process");
              char* args = "Hello World\0";
              execv("./prog1",args);
              printf("Execv exected. Exiting main process");
            }
            Will the second print statement be executed?
          Company_tags: None
          Level: None
          Reference:
            - https://linuxhint.com/linux-exec-system-call/
          Answer:
            - Hint: Exec repalces the process that calls it.
            - Solution: |
                No. the second print statement will not be printed. It is because the exec() system call replaces the process that calls it.
                So, when exec() will be executed, it will execute the code that it's .c file contains. The main process gets replaced so it
                does not exist from the moment the exec() system call starts executing.
                Also remember, as the process created by exec() is assigned the PID of the calling process, it also repalces the address space
                of the calling process. This is why we say that the original process does not exist after the exec system call.
        - Question_3: |
            If a proces has PID as 'x'. Suppose it executes exec() at some pint of time.
            What will be the PID of the process (created due to the exec() call)?
          Company_tags: None
          Level: None
          Options:
            - 1: x
            - 2: anything greater than x
            - 3: anything less than x
            - 4: Can't say
          Correct_answer: 1
          Answer:
            - Hint: exec() replaces the calling process.
            - Solution: |
                The PID of the new process created due to exec() will be 'x' itself. The explanation is simple that the exec() process replaces
                the original calling process. So, if you execute a print statement that will print the PID of the process, both will print 'x'.
        - Question_4: |
            If process P1 creates 2 processes P2 and P3. Who will be the previous sibling of P2 and
            who will be the next sibling of P1, respectively?
          Company_tags: None
          Level: None
          Options:
            - 1: P1 and P2 respectively
            - 2: P1 and P2 respectively
            - 3: P3 and P3 respectively
            - 4: P2 and P1 respectively
          Correct_answer: 2
          Answer:
            - Hint:
            - Solution: The next sibling of the parent is the last last child it creates and the previous sibling of the 1st child is parent itself.
        - Question_5: What is the return value of fork()?
          Company_tags: None
          Level: None
          Answer:
            - Hint: There are two.
            - Solution: >
                It returns the PID of the child to the parent process (i.e, if the fork() is successful), else it returns '-1'.
                As for the second return value, it returns '0' to the child that is created.
        - Question_6: |
            Let there be two concurrent processes P1 and P2.
              P1 -> {
                //some code
                x++;
                //remaining code
              }
              P2 -> {
                //some code
                x--;
                //remaining code
              }
            Let the initial value of x be zero (0). What will be minimum value of “x” after these processes complete their execution?
            (Assume the “some code” and “remaining code” do not modify x)
          Company_tags: None
          Level: None
          Option:
            -1: 0
            -2: 1
            -3: 2
            -4: -1
          Correct_answer: 4
          Answer:
            - Hint:
            - Solution: |
                This has to do with the possibility of context switch at any time during the execution of x++ or x--.
                “x--” essentially means,
                load 'x' in a reg; ---(1)
                Reduce the 'reg' by '1'; ---(2)
                store 'x' in the 'reg';  ---(3)
                Similar is the case with “x++". Now if there is a context switch after (1), then if “x++” executes and then (2) and (3)
                executes, the value in “reg” will be zero before context switch and after executing “x++” also, “reg” will contain zero.
                And hence after stage 2 and 3, final value of x will be “-1”. Similarly, the max value of x can be 1.
        - Question_7: |
            Find the total number of new processes created. What will the process tree
            look like?
            Assume that the necessary libraries are included and that the fork() call produces child processes and does not give '-1'
            (which is return when fork does not happen successfully).
            int main()
            {
              printf("fork program starting with pid %d\n",getpid());
              if(fork())
                if(!fork())
                  fork();
              printf("My PID=%d My PPID=%d\n",getpid(),getppid());
              wait(NULL);
              wait(NULL);
              return 0;
            }
          Company_tags: None
          Level: None
          Reference: None
            - https://www.geeksforgeeks.org/creating-multiple-process-using-fork/
            - https://linuxtrainers.wordpress.com/2014/12/31/how-fork-system-call-works-what-is-shared-between-parent-and-child-process/
            - https://unix.stackexchange.com/questions/87551/which-file-in-kernel-specifies-fork-vfork-to-use-sys-clone-system-call
          Correct_answer: 3
          Answer:
            - Hint:
            - Solution: |
                Please go through the reference material for this question if you are stuck.
                Now, for the solution part, remember that the return value for fork is 'zero' for the child and 'the PID of the child' to the
                parent.
                So, when the parent process executes the fork() call, it will create a new process and the PID of the process will be the
                return value in the 'if condition' of the parent process, so it will go to the 'inner if condition'. But, as for the 1st child
                process, the value will be 'zero' in it's 'if condition', this is because the return value of fork is 'zero for the child.
                Then, the child begins the exectution at the same point where the fork() calls returns execution to the main program. But
                because it does not satisfy the 1st 'if condition', it goes on to print and exit. Then, the parent forks one more process.
                The child that is created will move ahead in the 'if condition' tree as '!0' evalutes 'true' for the inner 'if condition'.
                So, it goes inside that and executes one more fork(). As for the parent, it does not go ahead in the 'if condition' as '!PID'
                evalutes as false. Note that PID zero is permanantly assigned to the 'swapper process' or 'sched process'. So, '!PID' will
                always always be 'false'. So, it will wait for the two children to finish exectution (two because of two wait() calls). In
                this way, there will be three new processes created.
                As for the process tree, it will be like this:
                                        P1 -----> Parent Process
                                      /  \
                                     /    \
                      1st child<----P2     P3---->2nd child
                                            \
                                             P4----->1st child of 2nd child
        - Question_8: |
            What will be the value of 'x' in each print statement? Assume all processes will be created.
            int x=0;
            int main()
            {
              if(fork())
                x=x+5;
              else if(!fork())
              {
                x=x+10;
                printf("PID = %d X=%d\n",getpid(),x);
                exit(0);
              }
              else
                x=x-2;
              x=x+15;
              printf("PID=%d and X =%d\n",getpid(),x);
              while(wait(NULL)!=-1);
                return 0;
            }
          Company_tags: None
          Level: None
          Reference:
            - https://www.geeksforgeeks.org/fork-memory-shared-bw-processes-created-using/
          Answer:
            - Hint:
            - Solution: |
                The parent process forks a child process and will go inside the if condition. It will increase 'x' by 5 and then by '15' and
                then wait till all of it's children to die (because of the while loop). The 1st child will not go inside the 'if condition'
                and will go to the 'else if' statement. But, it will not go inside the else if statement because of '!fork()' condition in
                the 'else if' statement. At the same time, due to a successful fork, the 1st child will create a child of it's own and
                that child will enter in the 'else if' statement. Concurrently, the 1st child of the parent will keep on going forward. So,
                it will execute the else condition and decrease the value of 'x' by '2' and then increase it by '15'. This child did not have
                the value of 'x' to be '5' initially because when it was created, the value of 'x' was 'zero'.This is because of the simple
                reason that the child contains a copy of all the variables that the parent had at the time of forking (except for the shared
                variables, which are same for both for parent and child). Then, the 1st child of the parent process will also wait for it's
                child to exit. The child of the 1st child, will execute the statements inside of the 'else if' statement and exit with status
                '0'. The value of 'x' in this process (child of the child of the parent process) will thus be '0+10',i.e., '10'.
                So, the value of 'x' in parent process will be '0+5+15'='20' and that in 1st child will be '0-2+15'='13'. Here is the process
                tree:
                                                        P1-----> Parent process, x=20
                                                       /
                                                      P2------>1st child, x=13
                                                     /
                                                    P3------>child of the child of parent, x=10
        - Question_9: Why can't a forked process have a PID as 0 or 1?
          Company_tags: None
          Level: None
          Reference:
            - https://unix.stackexchange.com/questions/83322/which-process-has-pid-0
            - https://hackernoon.com/the-curious-case-of-pid-namespaces-1ce86b6bc900
          Answer:
            - Hint:
            - Solution: |
                A process can have a PID between 0 and 32767. The upper range can be found in your system's '/proc/sys/kernel/pid_max' file.
                It is generally '32767'. But, the process that you create using fork cannot be assigned a PID '0' or '1'. This is because
                the PID '0' is given to first process that the OS creates and this process is generally the 'swapper process' or 'sched
                process'. This process is responsible for the paging in your system. This process dies or exits when the OS shuts down. So,
                this PID is never vacant. Then, PID '1' is the 'init process'. When this process dies, all the process are killed with the
                kill() signal. So, this is why a forked process cannot have a PID '0' or '1'.
        - Question_10: Explain in brief what happens during the fork() system call.
          Company_tags: None
          Level: None
          Reference:
          Answer:
            - Hint:
            - Solution: |
                The following steps take place when a fork() executes:
                - A slot is allocated in the process table for the new process.
                - A unique process id is assigned to the new process.
                - A copy of the process image of the parent is made, with the exception of shared memory.
                - fork() also increases counters for any files owned by the parent, to reflect that an additional process now also owns
                  these files.
                - The kernel (during the fork() call) also assigns the child process to a ready to run state.
                - A Process ID number (PID) of the child to the parent process and a 0 value to the child process is returned.
                - After completing these functions, OS will do the following operations as a part of dispatcher routine:
                  • Control returns to the user mode at the point of the fork call of the parent
                  • Transfer control to the child process. The child process begins executing at the same point in the code as the parent,
                  namely at the return from the fork call, i.e, the instruction next in line after fork().
                  • Transfer control to another process. Both child and parent are left in the ready to run state.
        - Question_11: What is the difference between fork() and vfork()?
          Company_tags: None
          Level: None
          Reference:
            - https://www.quora.com/What-is-the-difference-between-fork-and-vfork
          Answer:
            - Hint:
            - Solution: |
                • vfork() is a variant of fork() and it behaves exactly like fork() except that it does not make a copy of the address
                  space and page table of the parent process.
                • Memory including stack space is shared by the parent and the child process.
                • vfork() suspends the parent process until the child releases its memory address space, i.e., until the child makes a call
                  to exec() or _exit().
        - Question_12: Explain Copy-On-Write (COW) mechanism.
          Company_tags: None
          Level: None
          Reference:
            - https://unix.stackexchange.com/questions/58145/how-does-copy-on-write-in-fork-handle-multiple-fork
            - https://www.reddit.com/r/compsci/comments/31szui/trying_to_understand_fork_and_copyonwrite_cow/
          Answer:
            - Hint: Lazy approach.
            - Solution: |
                Today's systems run with hundreds and thousands of processes. If, the system will go according to the rules and copy the memory
                in use by the parent process after every for(), it will be very time consuming as it will involve context switche. So, to avoid
                this, the OS waits until any one of the parent or child modifies the memory. When any one of them does, it then makes the two
                copies of memory it was supposed to do at the begining of the fork().
                Additionally, as processes recide in virtual memory, whenever the child want to read something, it reads from the parent,
                provided, it has not written since it was created. But, as soon as it writes for the first time, before that write, the
                required copy of the parent memory is made (as it should have been in the start of the fork() call) and the child's memory
                space is updated to the new copy that is made and then the child process writes to the newly created memory space. This is COW.
        - Question_13: Explain the difference between wait() and waipid(). What are the different parameters of the two functions?
          Company_tags: None
          Level: None
          Reference:
            - http://poincare.matf.bg.ac.rs/~ivana/courses/ps/sistemi_knjige/pomocno/apue/APUE/0201433079/ch08lev1sec6.html
            - https://webdocs.cs.ualberta.ca/~tony/C379/C379Labs/Lab3/wait.html
          Answer:
            - Hint:
            - Solution: |
                wait() waits for a child to terminate. It will be temporarily blocled till then. Whereas, waitpid can be either blocking or
                non-blocking:
                - If options is 0, then it is blocking.
                - If options is WNOHANG, then is it non-blocking.
                WNOHANG is one of the options of the 'options' parameter of the waitpid function.
                If more than one child is running then, wait() returns when the first time one of the child exits. Whereas, waitpid() is more
                versatile. It's 'pid' parameter provides that versatility. If:
                - pid < -1 means that it has to wait for any child process whose process group ID is equal to the absolute value of pid to
                  exit.
                - pid = -1 means that it has to wait for any child process to exit. At this point, it is equivalent to wait().
                - pid = 0 means that it has to wait for any child process whose process group ID is equal to that of the calling process.
                - pid > 0 means that it has to wait for the child whose process ID is equal to the value of pid.
                In this way, it is different than the wait() function.
        - Question_14: What is the difference between the 'exec' functions suffixed with 'p' and 'e'?
          Company_tags: None
          Level: None
          Reference:
          Answer:
            - Hint: Need of specifying path variable.
            - Solution: |
                The 'exec' functions which end with the suffx 'p' will search the current PATH variable to find the executable file. Whereas,
                the 'exec' functions suffixed with 'e' have to be given the PATH variable as an input parameter and then it will find the
                file to be executed in that PATH variable.
                Note: PATH variable is address of the file in terms of directories. For example: a file can have it's PATH variable as
                      "/home/mypc/Downloads/myfolder"
      Premium/Quiz_questions:
        - Question_1: >
            Consider a process with multiple threads.
            What would happen if one of the threads crashes due to fault?
          Company_tags:
          Level:
          Reference:
            - https://stackoverflow.com/questions/36423511/what-happen-if-thread-crashes-which-is-better-thread-or-process
          Comment:
          Options:
            - 1: Only, Thread with the fault crashes
            - 2: Entire process crashes
            - 3: Undefined behavior
            - 4: Cannot be predicted, either of the options can happen
          Correct_answer: 2
          Answers:
            - Hint: Threads share their address space.
            - Answer: |
                If one thread crashes due to a segmentation fault or any other error, all other threads and the entire process are killed.
                This is because the threads are part of the same process space, so it doesn't generally make any sense to keep going if a
                thread has caused a fault signal. A crash signal (like SIGSEGV, SIGBUS, SIGABRT) means that you have lost control over
                the behavior of the process and anything could have happened to its memory. There is a negative side of entire process being
                killed due to a fault in one of the threads. This situation can lead to data and system corruption if the other threads were
                in the middle of some important task. Due to this reason, important & independent tasks are generally performed as a separate
                process, such that crashing of one does not bring down the entire fucntionality.
  - Thread:
    Resouces:
      - GeeksForGeeks: https://www.geeksforgeeks.org/thread-in-operating-system/
      - Tutorials Point: https://www.tutorialspoint.com/operating_system/os_multi_threading.htm
      - Neso Academy: https://www.youtube.com/watch?v=LOfGJcVnvAk
    Practice_questions:
      - Question_1: What is the difference between User threads, kernel threads and kernel-level-threads?
        Company_tags: None
        Level: None
        Reference:
          - https://stackoverflow.com/questions/15983872/difference-between-user-level-and-kernel-supported-threads
        Correct_answer: None
        Answers:
          - Hint: None
          - Solution: |
              #Will write soon.
      - Question_2: >
          Consider a process with multiple threads.
          What would happen if one of the threads crashes due to fault?
        Company_tags:
        Level:
        Reference:
          - https://stackoverflow.com/questions/36423511/what-happen-if-thread-crashes-which-is-better-thread-or-process
        Comment:
        Options:
          - 1: Only, Thread with the fault crashes
          - 2: Entire process crashes
          - 3: Undefined behavior
          - 4: Cannot be predicted, either of the options can happen
        Correct_answer: 2
        Answers:
          - Hint: Threads share their address space.
          - Solution: |
              If one thread crashes due to a segmentation fault or any other error, all other threads and the entire process are killed.
              This is because the threads are part of the same process space, so it doesn't generally make any sense to keep going if a
              thread has caused a fault signal. A crash signal (like SIGSEGV, SIGBUS, SIGABRT) means that you have lost control over
              the behavior of the process and anything could have happened to its memory. There is a negative side of entire process being
              killed due to a fault in one of the threads. This situation can lead to data and system corruption if the other threads were
              in the middle of some important task. Due to this reason, important & independent tasks are generally performed as a separate
              process, such that crashing of one does not bring down the entire fucntionality.
      - Question_3: What are the benefits of using a thread, instead of using a process?
        Company_tags:
        Level:
        Reference:
          - https://www.tutorialspoint.com/operating_system/os_multi_threading.htm
        Answers:
          - Hint: Lightweight, easy to manage, etc.
          - Solution: |
              - Threads Share memory & other resources of the process it belongs to.
              - Therads are more economical to context switch.
              - Threads can run in parallel and hence multiple tasks can be done parallely.
              - Threads are also easy to create, switch between and terminate.
      - Question_4: What is the difference between Data and Task Parallelism?
        Company_tags:
        Level:
        Reference:
          - https://en.wikipedia.org/wiki/Task_parallelism
        Answer:
          - Hint:
          - Solution: |
              Data Parallelism is distributing data to and running them through the same task (thread/process). Task Parallelism is running
              different tasks on different cores on the same data.
              Both these Parallelism can be visualised as follows:
              - Data Parallelism------------>
                                                    -------------------DATA-----------------
                                                  /                                          \
                                                  --------------------------------------------
                                                 |    D0    |    D1    |    D2    |    D4     |
                                                  --------------------------------------------
                                                    |             |          |          |
                                                  Core-1        Core-2     Core-3     Core-4

              - Task Parallelism------------>
                                                    -------------------DATA-----------------
                                                  /                                          \
                                                  --------------------------------------------
                                                 |                                            |
                                                  --------------------------------------------
                                                    /             /             \             \
                                                  Core-1        Core-2         Core-3       Core-4

      - Question_5: Why does the return value of a thread function be of the type "(void *)" only?
        Company_tags:
        Level:
        Reference:
          - https://en.wikipedia.org/wiki/Task_parallelism
        Answer:
          - Hint:
          - Solution: |
              #Will write soon
      - Question_6: |
          What does "getpid()" function return when executed in a thread? Does it give an error? If not, what is the return value?
        Company_tags:
        Level:
        Reference:
          - https://stackoverflow.com/questions/9305992/if-threads-share-the-same-pid-how-can-they-be-identified
        Answer:
          - Hint: Not an error.
          - Solution: |
              No, It will not give an error. If you call the function "getpid()" inside a thread, you will get the PID of the thread that created
              it. If you execute that function in a newly created thread (by a process), you will get the PID of the process that created it. So,
              executing "getpid()" function in a thread will give you the PID of the process that created it.
              Note: You can think of a thread as a process that shares it's address space with it's parent process.
      - Question_7: >
          Like a process has a PID, does a thread have something similar to PID that the LINUX system uses to identify it(that thread)?
        Company_tags:
        Level:
        Reference:
          - https://stackoverflow.com/questions/21091000/how-to-get-thread-id-of-a-pthread-in-linux-c-program
        Answer:
          - Hint: Using a System Call.
          - Solution: |
              Yes, there is a TID of a thread. We can get it by executing the system call "syscall(__NR_gettid)" in the thread (whose TID we
              want to know).
      - Question_8: If I create a thread and the return value as '0', does it mean that the creation has failed? Explain.
        Company_tags:
        Level:
        Reference:
          - https://stackoverflow.com/questions/21091000/how-to-get-thread-id-of-a-pthread-in-linux-c-program
        Answer:
          - Hint: Not failed.
          - Solution: |
              No, getting '0' as a return value does not mean that the thread creation has failed. When you create a thread using the
              "pthread_create()" function, the kernel stores the identifier of th enewly created thread in the location pointed by the argument
              in the function. And if the creation is successful, a '0' is returned.
      - Question_9: What is the "detachable state" of a thread?
        Company_tags:
        Level:
        Reference: None
        Answer:
          - Hint: Release of the holding resources.
          - Solution: |
              Detachable thread means that when it terminates, it will release all the resources that it is was allocated. A thread is in
              "Joinable State" by default. If you want to make the thread detachable, you need to make it explicitly using the "pthread_detach()"
              function and passing the thread as the argument.
      - Question_10: What happens if a thread executes the fork() call?
        Company_tags:
        Level:
        Reference:
          - https://stackoverflow.com/questions/39890363/what-happens-when-a-thread-forks
          - http://gauss.ececs.uc.edu/Courses/c694/lectures/ForksThreads/forks.html
        Answer:
          - Hint:
          - Solution: |
              #Will write later
      - Question_11: What is the difference between fork() and clone() system call?
        Company_tags:
        Level:
        Reference:
          - https://unix.stackexchange.com/questions/199686/fork-vs-clone-on-2-6-kernel-linux
          - http://man7.org/linux/man-pages/man2/clone.2.html
        Answer:
          - Hint: Seperate address space or not.
          - Solution: |
              #Will write later
      - Question_12: What are signals? What are they used for? How are they used?
        Company_tags:
        Level:
        Reference:
          - https://en.wikipedia.org/wiki/Signal_(IPC)
          - https://www.usna.edu/Users/cs/aviv/classes/ic221/s16/lec/19/lec.html
        Answer:
          - Hint: A form of Inter Process Communication (IPC).
          - Solution: |
              Signal are software interrupts that are used by processes and threads to communicate between each other. They can be used to tell
              that a particular task is completed, kill a process/thread, if an exception occurs, build user-defined procedures, communicate
              between processes, etc. Basically, signals are used for IPC.
              How they are used:
              - Same signal to all the threads.
              - Same signals to some of the thread, and some other signal to others.
              - A signal only for one specific thread.
              - All signals to a specific thread.
      - Question_13: What is Thread Pool and how can it be used at PC startup? #Or some question on thread pool
        Company_tags:
        Level:
        Reference:
          - https://softwareengineering.stackexchange.com/questions/173575/what-is-a-thread-pool
        Answer:
          - Hint:
          - Solution: #Will write soon
      - Question_14: #Thread Specific Data
        Company_tags:
        Level:
        Reference:
          - http://poincare.matf.bg.ac.rs/~ivana/courses/ps/sistemi_knjige/pomocno/apue/APUE/0201433079/ch12lev1sec6.html
        Answer:
          - Hint:
          - Solution: #Will Write Soon
      - Question_15: #Thread Cancellation
        Company_tags:
        Level:
        Reference:
          - https://www.tutorialspoint.com/what-is-thread-cancellation
        Answer:
          - Hint:
          - Solution: #Will Write Soon
Scheduling:
  - Process Scheduling:
    Resouces:
      - https://www.tutorialspoint.com/operating_system/os_process_scheduling.htm
      - https://www.studytonight.com/operating-system/process-scheduling
    Practice_questions:
      - Question_1: Of the three types of schedulers present in an OS, which executes most frequently?
        Options:
          - 1: Short Term Scheduler
          - 2: Mid Term Scheduler
          - 3: Long Term Scheduler
        Company_tags:
        Level:
        Reference:
        Correct_answer: 1
        Answer:
          - Hint:
          - Solution: |
              Short Term Scheduler is executed most frequently because it is responsible for selecting the next process to be executed. It is
              also known as dispatcher.
      - Question_2: Long Term Scheduler controls the degree of multiprogramming. True or False?
        Company_tags:
        Level:
        Correct_answer: "True"
        Reference:
        Answer:
          - Hint:
          - Solution: |
              It is true because long term scheduler is responsibe for selecting a process to be brought into the ready queue. Now, if
              the long term scheduler is not called frequently enough, the ready queue may become empty and thus there may not be multi-
              programming.
      - Question_3: What are the conditions under which a non-preemtive process leaves the CPU (i.e., a voluntary preemption occurs)?
        Company_tags:
        Level:
        Reference:
          - https://www.geeksforgeeks.org/preemptive-and-non-preemptive-scheduling/
        Answer:
          - Hint:
          - Solution: |
              - When the process reaches termination.
              - When the process voluntarily goes into waiting state.
              Note: Except these conditions, rest all conditions lead to non-voluntary preemption.
      - Question_4: What is the difference between a scheduler and a dispatcher?
        Company_tags:
        Level:
        Reference:
          - https://www.geeksforgeeks.org/difference-between-dispatcher-and-scheduler/
        Answer:
          - Hint:
          - Solution: |
              A dispatcher comes into action after short-term scheduler selects a process that will get a chance to execute in the CPU. Thus,
              the dispatcher is a module that gives a process control over the CPU. This involves the following steps:
              - Switching context
              - Switching to user mode
              - Jumping to proper location in the user program to restart that program.
      - Question_5: What are the Scheduling Criteria that we need to keep in mind while designing a scheduling algorithm?
        Company_tags:
        Level:
        Reference:
          - https://www.youtube.com/watch?v=bWHFY8-rL5I
        Answer:
          - Hint:
          - Solution: |
              - CPU Utilization: Making sure that maximum of the CPU is utilized most of the time and that utilization is productive. As we
                                 will see in deadlocks, the CPU maybe executing a wait function indefinitely and then though it will be busy,
                                 it will not be productive.
              - Throughput: We need to be sure that the throughput of the system is maximum.
              - Turnaround Time: If a process is submitted then the time till it's completion should be minimum.
              - Deadlines: Maximum number of processes must meet their deadlines (real time processes).
              - Response Time: If a process requests something, then it must be granted that as soon as possible.
  - CPU Scheduling Algorithms:
    Resources:
      - https://www.guru99.com/cpu-scheduling-algorithms.html
      - https://www.studytonight.com/operating-system/cpu-scheduling-algorithms
Miscellaneous:
  - Practice_questions:
      - Question_1: |
            S1: If an entry is not found in the page table, the page table is not invalid. Rather, it is fetched because loading a page
                table is a dynamic job.
            S2: The frame size in a frame table can be 4KB or 4MB in a 32-bit system.
        Options:
          -1: TRUE/TRUE
          -2: TRUE/FALSE
          -3: FALSE/TRUE
          -4: FALSE/FALSE
        Reference:
          - https://cs.stackexchange.com/questions/47541/is-page-size-always-equal-to-frame-size
        Company_tags:
        Level:
        Correct_answer: 1
        Answer:
          - Hint:
          - Solution: |
              If the frame entry is not found in a page table, we so to swap space and bring back the entry. But any entry that is beyond the
              Page Table Limit Register is invalid. This type of loading is done because it is dynamic in nature. The frame size depends on
              the implementation of the architecture. It is generally 4KB or 4MB. But, you can modify it to what you want.

      - Question_2: |
          What is the effective access time of memory when there is an 80% hit in TLB and the access time for TLB is 20ns and that of the
          memory is 100ns?
        Company_tags:
        Level:
        Options:
          -1: 140ns
          -2: 150ns
          -3: 80ns
          -4: 160ns
        Correct_answer:
        Answer:
          - Hint:
          - Solution: |
              The correct answer is option b. Hit percentage means out of 100, how many memory accesses were present in TLB. For example,
              if hit percentage is 80%, 60% of the time, we find what we need to access and the other 20% of the time, we do not and hence
              there is an exception and the CPU takes over, loads that memory page location into the TLB and again execute the instruction.
              Therefore, 80% hit means 80% successful accesses but, out of 80%, the first 60 are successful the first time and the remaining
              20 the second time, after the CPU loads them into the TLB. No that we are clear with hit percentage, the question is pretty simple.
              Effective access time = ((hit%*(TLB access time + Memory access time))  + ((1-hit%)*(Memory access time + TLB access time)))/hit%
              = (0.8*(100+20) + (100+20))/0.8 = 150ns
              Now we have multiplied (1-hit%) with 120 because, once it will search the TLB for the page location, then when it will not find it,
              it will access the memory and load it into TLB.
      - Question_3: >
          S1: System Library (libc.so) is linked at compile time and Shared Library (libm.so) is linked dynamically.
          S2: If a process is swapped, it can return to any address at swapping back to main memory.
          Please select the correct option, where “TRUE/TRUE” indicates that S1 is TRUE and S2 is TRUE.
        Company_tags:
        Level:
        Options:
          -1: TRUE/TRUE
          -2: TRUE/FALSE
          -3: FALSE/TRUE
          -4: FALSE/FALSE
          Correct_answer: 2
          Answer:
            - Hint:
            - Solution: |
                The statement S1 is true and is a fact. The second statement is not always true. Swapped out process must return to the same
                address if they had binding that was done compile time or load time. This is the reason why we share a driver file and not
                the compiled file.
      - Question_4: Which of the following will guarantee a deadlock in a single instance resource?
        Company_tags: abc
        Level: xyz
        Options:
          -1: Mutual Exclusion
          -2: Circular Wait for graph
          -3: Hold and Wait
          -4: Preemption of one of the process.
        Correct_answer: 2
        Answer:
          - Hint: Single instance resource and circular wait are related.
          - Solution: |
              The correct option is b. This is because if every process in the graph is holding a resource and requesting for other and another
              process is requesting for the resource the first is holding there is a definite deadlock. The others do not guarantee that.
      - Question_5: Trap Bit question.
        Company_tags: abc
        Level: xyz
        Reference:
          - https://stackoverflow.com/questions/13185300/where-is-the-mode-bit
          - https://stackoverflow.com/questions/28815848/does-each-core-has-its-own-private-set-of-registers
          - http://www.cs.cornell.edu/courses/cs3410/2012sp/lecture/22-traps-i-g.pdf
        Answer:
          - Hint:
          - Solution: #Will write soon
  - Premium/Quiz_questions:
      - Question_1: >
          A user space process crash can be handled gracefully by exception handling. Is it possible to
          gracefully handle a crash in kernel driver for a monolithic kernel like LINUX?
        Company_tags:
        Level:
        Reference:
          - https://stackoverflow.com/questions/32644692/why-kernel-cant-handle-crash-gracefully
          - Chapter 8, Topic - Kernel Basics, Mac OS X and iOS Internals, Jonathan Levin
        Comment:
        Options:
          - No, a crash in kernel driver would simply crash the whole kernel leading to kernel panic
          - Yes, we can continue running the kernel. Simply crashing the faulty kernel driver is enough
          - Yes, we can continue running the kernel. We need to crash faulty driver and all its associcated entities
          - None of these
        Correct_answer: 1
        Answers:
          - Hint: For monolithic kernels like LINUX, the kernel module and the kernel itself share the same address space.
          - Solution: |
              LINUX uses a monolithic kernel architecture. A monolithic kernel is an operating system architecture where all
              the operating system components(including the device drivers, file system, and the application IPC) are working
              in a single kernel address space. Due to such type of design, there is no protection boundary between modules. If a
              kernel module starts misbehaving, it can overwrite memory from another subsystem. So, when a driver crashes,
              it may or may not stay local to that driver. It is not possible to know if it has poisoned the kernel memory.
              Security is the major reason behind the design of crashing the entire kernel on occurence of a kernel driver crash.
              This is not the case with userspace processes. This is because the address space for each process is separate
              and so it is possible to catch erroneous memory access(or any other fault) and terminate the process.
              Microkernels(in which services have separate address space) can overcome this situation. Whereas,
              Hybrid kernels(Windows and MacOS) also face this issue due to their adoption/essence of monolithic kernel design.
